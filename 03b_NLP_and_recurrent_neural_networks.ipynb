{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03b_NLP_and_recurrent_neural_networks.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMI3Tp62bWGley/BwEdiguY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/introNLP/blob/master/03b_NLP_and_recurrent_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdoE59GqVfhi",
        "colab_type": "text"
      },
      "source": [
        "# Pre-trained Word Embeddings and RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dRBQ88DscTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 3773\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS7TAPJruzr7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cf8c5bf7-44f3-447f-9eb1-7eeb2d0e3c9d"
      },
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:02<00:00, 38.5MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDDzCMY3u-46",
        "colab_type": "code",
        "outputId": "deb7ff0f-c354-4ca8-97dc-e06add485bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Number of training examples: {}\".format(len(train_data)))\n",
        "print(\"Number of testing examples: {}\".format(len(test_data)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ572Bd_wC6h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4cf402fb-181e-4f1c-d515-8d17b8cda2fa"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['Diagnosis', 'Murder', 'has', 'been', 'shown', 'on', 'most', 'Weekday', 'afternoons', 'on', 'BBC1', 'since', 'I', 'used', 'to', 'watch', 'it', 'while', 'ill', 'from', 'School', 'a', 'good', '10', 'years', 'ago', '-', 'I', 'know', 'I', 'should', \"n't\", 'really', 'enjoy', 'it', ',', 'in', 'the', 'same', 'way', 'I', 'should', \"n't\", 'enjoy', \"'\", 'Murder', 'she', 'Wrote', \"'\", 'but', 'I', \"'m\", 'totally', 'addicted', 'to', 'both', 'and', 'even', 'have', 'the', 'DVD', 'box', '-', 'sets', '....', 'OK', 'I', 'know', 'that', \"'s\", 'sad!<br', '/><br', '/>Dick', 'Van', 'Dyke', 'carries', 'the', 'show', 'as', 'he', 'stars', 'as', 'Dr', '.', 'Mark', 'Sloan', 'a', 'Doctor', 'at', 'Community', 'General', 'Hospital', 'in', 'L.A', 'who', 'is', 'also', 'a', 'Police', 'consultant', 'for', 'the', 'L.A.P.D.', '-', 'his', 'son', 'Steve', '(', 'Barry', 'van', 'Dyke', '-', 'Dick', \"'s\", 'real', 'life', 'son', ')', 'is', 'a', 'Police', 'Officer', ',', 'who', 'needs', 'his', 'father', \"'s\", 'help', 'on', 'very', 'many', 'Suspicious', 'deaths', '.', '<', 'br', '/><br', '/>Along', 'for', 'the', 'ride', 'is', 'Dr', '.', 'Amanda', 'Bentley', '(', 'Victoria', 'Bentley', ')', 'the', 'resident', 'Pathologist', 'at', 'Community', 'General', 'and', 'for', 'the', 'first', 'couple', 'of', 'seasons', 'you', 'had', 'Scott', 'Baio', 'playing', 'Dr', '.', 'Jack', 'Stewart', ',', 'who', 'upped', 'and', 'left', 'the', 'series', 'in', '1995', 'hoping', 'to', 'go', 'on', 'to', 'bigger', 'and', 'better', 'things', '...', 'he', 'should', 'have', 'stayed', 'where', 'he', 'was', ',', 'he', 'has', \"n't\", 'done', 'anything', 'of', 'note', 'since', '....', 'and', 'his', 'only', 'theatrical', 'appearance', 'for', 'many', 'years', 'was', 'in', 'Baby', 'Geniuses', '2:Superbabies', '....', 'Oh', 'Dear!!!<br', '/><br', '/>anyhow', 'Dr', '.', 'Jack', 'Stewart', 'was', 'replaced', 'by', 'the', 'younger', 'Dr', '.', 'Jesse', 'Travis', 'played', 'by', 'Charlie', 'Schlatter', 'who', 'stepped', 'into', 'Baio', \"'s\", 'shoes', 'pretty', 'comfortably.<br', '/><br', '/>The', 'series', 'is', 'highly', 'implausible', 'but', 'what', 'Whodunit', 'series', 'is', \"n't\", '?', '(', 'Murder', 'she', 'wrote', '-', 'everywhere', 'Jessica', 'goes', ',', 'someone', 'ends', 'up', 'dead', ',', 'or', 'The', 'underrated', 'Father', 'Dowling', 'Mysteries', 'about', 'a', 'Murder', 'solving', 'Priest', 'with', 'nun', 'sidekick)<br', '/><br', '/>The', 'series', 'was', 'much', 'lighter', 'up', 'until', '1997', 'this', 'is', 'because', 'it', 'had', 'a', 'supporting', 'cast', 'that', 'included', 'the', 'bumbling', 'Hospital', 'Manager', 'Norman', 'Briggs', 'played', 'by', 'Michael', 'Tucci', 'along', 'with', 'Nurse', '&', 'Mark', \"'s\", 'secretary', 'Dolores', 'played', 'by', 'Delores', 'Hall', ',', 'After', '1997', 'both', 'these', 'characters', 'were', 'no', 'longer', 'included', 'and', 'the', 'series', 'became', 'a', 'grittier', 'affair', 'with', 'a', 'bigger', 'looking', 'budget', ',', 'some', 'episodes', 'included', 'far', 'more', 'action', ',', 'one', 'episode', 'the', 'entire', 'Hospital', 'is', 'blown', 'up.<br', '/><br', '/>This', 'was', 'a', 'family', 'show', 'For', 'the', 'Van', 'Dyke', \"'s\", 'because', 'as', 'well', 'as', 'Dick', \"'s\", 'Son', 'Barry', ',', 'you', 'also', 'had', 'Dick', \"'s\", 'Daughter', 'And', 'all', 'his', 'Grandchildren', 'making', 'an', 'appearance', 'in', 'various', 'episodes', '.', '<', 'br', '/><br', '/>As', 'the', 'series', 'went', 'on', 'it', 'got', 'a', 'bit', 'silly', ',', 'one', 'episode', 'I', 'remember', 'Dick', 'van', 'Dike', 'plays', 'his', 'entire', 'family', ',', 'which', 'was', 'a', 'bit', 'out', 'of', 'the', 'ordinary', ',', 'but', 'on', 'the', 'Whole', \"'\", 'Diagnosis', 'Murder', \"'\", 'was', 'a', 'really', 'good', 'TV', 'show', 'which', 'had', 'numerous', 'good', 'Guest', 'Stars.<br', '/><br', '/>Since', 'this', 'show', 'finished', 'in', '2001', ',', 'Dick', '&', 'Barry', 'have', 'appeared', 'together', 'again', 'in', 'the', \"'\", 'MURDER', '101', \"'\", 'series', 'of', 'TV', 'Movies', 'made', 'by', 'The', 'Hallmark', 'Channel', ',', 'pretty', 'much', 'following', 'the', 'same', 'path', ',', 'and', 'still', 'enjoyable', '.', 'Dick', 'who', \"'s\", 'now', 'in', 'his', 'mid', '80', \"'s\", 'does', \"n't\", 'seem', 'to', 'change', 'a', 'great', 'deal', ',', 'and', 'looks', 'as', 'if', 'he', \"'ll\", 'be', 'working', 'till', 'the', 'bitter', 'end.<br', '/><br', '/>TV', 'SHOW', '*', '*', '*', '*', 'OUT', 'OF', '*', '*', '*', '*', '*'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM5CtAGe2eho",
        "colab_type": "code",
        "outputId": "4cdeed70-5326-4cb0-c95c-191a2a40710c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(\n",
        "    random_state=random.seed(SEED),\n",
        "    split_ratio=0.8\n",
        ")\n",
        "\n",
        "print(\"Number of training examples: {}\".format(len(train_data)))\n",
        "print(\"Number of validation examples: {}\".format(len(valid_data)))\n",
        "print(\"Number of testing examples: {}\".format(len(test_data)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nul-rT84zAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 8185\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXyHKPd054Am",
        "colab_type": "code",
        "outputId": "b265143e-27bc-4761-8acc-4328250d878a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Unique tokens in TEXT vocabulary: {}\".format(len(TEXT.vocab)))\n",
        "print(\"Unique tokens in LABEL vocabulary: {}\".format(len(LABEL.vocab)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 8187\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAb8f32B6Jcp",
        "colab_type": "code",
        "outputId": "c3281193-f494-42e2-c5ee-6990b921e469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 232678), (',', 220840), ('.', 188920), ('and', 125362), ('a', 125266), ('of', 115884), ('to', 107654), ('is', 87196), ('in', 70206), ('I', 62349), ('it', 61298), ('that', 56438), ('\"', 50419), (\"'s\", 49667), ('this', 48419), ('-', 41945), ('/><br', 41022), ('was', 40196), ('as', 35006), ('with', 34063)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA--x2i66ejW",
        "colab_type": "code",
        "outputId": "fcc6822e-22a8-4701-daf7-2e498f489eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cCa8T_t8Tf9",
        "colab_type": "code",
        "outputId": "3cb1a3e2-57d1-4af9-ba6e-1a3cd3cbed55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f8591edf378>, {'pos': 0, 'neg': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVtV1PKW9nLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIg0PitTn1or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim,\n",
        "                 hidden_dim, output_dim,\n",
        "                 n_layers, bidirectional):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, sequences):\n",
        "\n",
        "        # sequences: (max sequences length, batch size)\n",
        "        seq_embeddings = self.embedding(sequences)\n",
        "\n",
        "        # seq_embeddings: (max sequences length, batch size, embedding dim)\n",
        "        seq_hidden, (hidden, cell) = self.rnn(seq_embeddings)\n",
        "\n",
        "        # hidden: (num_layers * num_directions, batch size, hidden dim)\n",
        "        hidden_concat = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "\n",
        "        # hidden_concat: (batch size, num_directions * hidden dim)\n",
        "        output = self.fc(hidden_concat)\n",
        "\n",
        "        # output: (batch size, 1) -> vector\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHQT54qZNjco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "model = RNN(INPUT_DIM,\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM,\n",
        "            OUTPUT_DIM,\n",
        "            N_LAYERS,\n",
        "            BIDIRECTIONAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdj7irbQEeur",
        "colab_type": "code",
        "outputId": "5caa8856-c329-408c-8782-5668142bd87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"The model has {:,} trainable parameters\".format(count_parameters(model)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,552,397 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1cy7BnqQ2Vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7d-2vJsRTXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpD93CtMU7fP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Precit y = 1 if sigmoid(output) >= 0.5 (positive review)\n",
        "    # Precit y = 0 if sigmoid(output) <  0.5 (negative review)\n",
        "    predictions = torch.round(torch.sigmoid(outputs))\n",
        "    correct = (predictions == labels).float()\n",
        "    return correct.sum() / len(correct)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMPz5h-knW0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, cruterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(batch.text).squeeze(1)\n",
        "\n",
        "        loss = criterion(outputs, batch.label)\n",
        "\n",
        "        acc = accuracy(outputs, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naN15Mx0joaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            outputs = model(batch.text).squeeze(1)\n",
        "\n",
        "            loss = criterion(outputs, batch.label)\n",
        "\n",
        "            acc = accuracy(outputs, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_sbes3gkmsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins, elapsed_secs = divmod(int(elapsed_time), 60)\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BasK5vKlEp3",
        "colab_type": "code",
        "outputId": "55857fe1-eb4b-4c2e-b0a1-801ade6428a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(\"Epoch: {:02} | Epoch Time: {}m {}s\".format(epoch+1, epoch_mins, epoch_secs))\n",
        "    print(\"\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%\".format(train_loss, train_acc*100))\n",
        "    print(\"\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%\".format(valid_loss, valid_acc*100))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.662 | Train Acc: 59.49%\n",
            "\t Val. Loss: 0.620 |  Val. Acc: 65.70%\n",
            "Epoch: 02 | Epoch Time: 0m 47s\n",
            "\tTrain Loss: 0.633 | Train Acc: 64.05%\n",
            "\t Val. Loss: 0.591 |  Val. Acc: 68.67%\n",
            "Epoch: 03 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.635 | Train Acc: 64.13%\n",
            "\t Val. Loss: 0.593 |  Val. Acc: 68.06%\n",
            "Epoch: 04 | Epoch Time: 0m 48s\n",
            "\tTrain Loss: 0.506 | Train Acc: 74.82%\n",
            "\t Val. Loss: 0.421 |  Val. Acc: 81.57%\n",
            "Epoch: 05 | Epoch Time: 0m 48s\n",
            "\tTrain Loss: 0.322 | Train Acc: 86.59%\n",
            "\t Val. Loss: 0.350 |  Val. Acc: 84.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X0OffS8rK5Q",
        "colab_type": "code",
        "outputId": "cb0ebc7f-f5ff-4739-efc4-b58504c585bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(\"Test Loss: {:.3f} |  Test Acc: {:.2f}%\".format(test_loss, test_acc*100))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.375 |  Test Acc: 82.45%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Noi_YI-O2a",
        "colab_type": "code",
        "outputId": "2f360084-48c6-476f-ca7b-868d6b30cc40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "iterator = iter(train_iterator)\n",
        "batch = next(iterator)\n",
        "print(batch.text.shape)\n",
        "print(batch.text[:,0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1103, 64])\n",
            "torch.Size([1103])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltpol6D2O7ol",
        "colab_type": "code",
        "outputId": "5b80c4bf-8ac4-49c2-bfb4-b59e6db9f758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = model.to(device)\n",
        "\n",
        "output = model(batch.text)\n",
        "\n",
        "print(output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}