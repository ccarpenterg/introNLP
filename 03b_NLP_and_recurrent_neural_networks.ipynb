{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03b_NLP_and_recurrent_neural_networks.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPrVC9aRztOpe5ox0+2ePos",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/introNLP/blob/master/03b_NLP_and_recurrent_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdoE59GqVfhi",
        "colab_type": "text"
      },
      "source": [
        "# Pre-trained Word Embeddings and RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dRBQ88DscTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 3773\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS7TAPJruzr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDDzCMY3u-46",
        "colab_type": "code",
        "outputId": "88e42ecc-a0c2-4144-f32c-475a884d3ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Number of training examples: {}\".format(len(train_data)))\n",
        "print(\"Number of testing examples: {}\".format(len(test_data)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ572Bd_wC6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM5CtAGe2eho",
        "colab_type": "code",
        "outputId": "bc97077c-9a32-4339-f69d-9ace566e4e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(\n",
        "    random_state=random.seed(SEED),\n",
        "    split_ratio=0.8\n",
        ")\n",
        "\n",
        "print(\"Number of training examples: {}\".format(len(train_data)))\n",
        "print(\"Number of validation examples: {}\".format(len(valid_data)))\n",
        "print(\"Number of testing examples: {}\".format(len(test_data)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nul-rT84zAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 8185\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXyHKPd054Am",
        "colab_type": "code",
        "outputId": "25f5b079-bc55-4c7d-9f46-1629cebbaf09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Unique tokens in TEXT vocabulary: {}\".format(len(TEXT.vocab)))\n",
        "print(\"Unique tokens in LABEL vocabulary: {}\".format(len(LABEL.vocab)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 8187\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAb8f32B6Jcp",
        "colab_type": "code",
        "outputId": "5d359473-7cf0-40b6-9f81-7143281564ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 232678), (',', 220840), ('.', 188920), ('and', 125362), ('a', 125266), ('of', 115884), ('to', 107654), ('is', 87196), ('in', 70206), ('I', 62349), ('it', 61298), ('that', 56438), ('\"', 50419), (\"'s\", 49667), ('this', 48419), ('-', 41945), ('/><br', 41022), ('was', 40196), ('as', 35006), ('with', 34063)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA--x2i66ejW",
        "colab_type": "code",
        "outputId": "95a348d5-6b13-44cc-d57a-d335c648eb47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cCa8T_t8Tf9",
        "colab_type": "code",
        "outputId": "12271274-e832-4587-bab1-d746e48b3df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fd2d4d5e378>, {'pos': 0, 'neg': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVtV1PKW9nLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIg0PitTn1or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim,\n",
        "                 hidden_dim, output_dim,\n",
        "                 n_layers, bidirectional):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, sequences):\n",
        "\n",
        "        # sequences: (max sequences length, batch size)\n",
        "        seq_embeddings = self.embedding(sequences)\n",
        "\n",
        "        # seq_embeddings: (max sequences length, batch size, embedding dim)\n",
        "        seq_hidden, (hidden, cell) = self.rnn(seq_embeddings)\n",
        "\n",
        "        # hidden: (num_layers * num_directions, batch size, hidden dim)\n",
        "        hidden_concat = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "\n",
        "        # hidden_concat: (batch size, num_directions * hidden dim)\n",
        "        output = self.fc(hidden_concat)\n",
        "\n",
        "        # output: (batch size, 1) -> vector\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHQT54qZNjco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "model = RNN(INPUT_DIM,\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM,\n",
        "            OUTPUT_DIM,\n",
        "            N_LAYERS,\n",
        "            BIDIRECTIONAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdj7irbQEeur",
        "colab_type": "code",
        "outputId": "84a066f7-83ee-43a1-89a5-5b4240bda407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"The model has {:,} trainable parameters\".format(count_parameters(model)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,552,397 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1cy7BnqQ2Vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7d-2vJsRTXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpD93CtMU7fP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Precit y = 1 if sigmoid(output) >= 0.5 (positive review)\n",
        "    # Precit y = 0 if sigmoid(output) <  0.5 (negative review)\n",
        "    predictions = torch.round(torch.sigmoid(outputs))\n",
        "    correct = (predictions == labels).float()\n",
        "    return correct.sum() / len(correct)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMPz5h-knW0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, cruterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(batch.text).squeeze(1)\n",
        "\n",
        "        loss = criterion(outputs, batch.label)\n",
        "\n",
        "        acc = accuracy(outputs, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naN15Mx0joaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            outputs = model(batch.text).squeeze(1)\n",
        "\n",
        "            loss = criterion(outputs, batch.label)\n",
        "\n",
        "            acc = accuracy(outputs, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_sbes3gkmsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_time * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BasK5vKlEp3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "47e33e85-f7c6-4e2a-976c-7f502377092c"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(\"Epoch: {:02} | Epoch Time: {}m {}s\".format(epoch+1, epoch_mins, epoch_secs))\n",
        "    print(\"\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%\".format(train_loss, train_acc*100))\n",
        "    print(\"\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%\".format(valid_loss, valid_acc*100))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m -2814s\n",
            "\tTrain Loss: 0.621 | Train Acc: 65.99%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 60.56%\n",
            "Epoch: 02 | Epoch Time: 0m -2980s\n",
            "\tTrain Loss: 0.585 | Train Acc: 69.34%\n",
            "\t Val. Loss: 0.616 |  Val. Acc: 65.47%\n",
            "Epoch: 03 | Epoch Time: 0m -2974s\n",
            "\tTrain Loss: 0.571 | Train Acc: 70.68%\n",
            "\t Val. Loss: 0.566 |  Val. Acc: 72.11%\n",
            "Epoch: 04 | Epoch Time: 0m -2997s\n",
            "\tTrain Loss: 0.368 | Train Acc: 84.13%\n",
            "\t Val. Loss: 0.348 |  Val. Acc: 84.75%\n",
            "Epoch: 05 | Epoch Time: 0m -2984s\n",
            "\tTrain Loss: 0.267 | Train Acc: 89.40%\n",
            "\t Val. Loss: 0.315 |  Val. Acc: 86.73%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X0OffS8rK5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5aac96d-266f-46d2-9cce-0494977c81d7"
      },
      "source": [
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(\"Test Loss: {:.3f} |  Test Acc: {:.2f}%\".format(test_loss, test_acc*100))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.362 |  Test Acc: 84.79%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Noi_YI-O2a",
        "colab_type": "code",
        "outputId": "2f360084-48c6-476f-ca7b-868d6b30cc40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "iterator = iter(train_iterator)\n",
        "batch = next(iterator)\n",
        "print(batch.text.shape)\n",
        "print(batch.text[:,0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1103, 64])\n",
            "torch.Size([1103])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltpol6D2O7ol",
        "colab_type": "code",
        "outputId": "5b80c4bf-8ac4-49c2-bfb4-b59e6db9f758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = model.to(device)\n",
        "\n",
        "output = model(batch.text)\n",
        "\n",
        "print(output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}