{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03b_NLP_and_recurrent_neural_networks.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP/Cri7XvjDDq2HJ3mqqrgr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/introNLP/blob/master/03b_NLP_and_recurrent_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdoE59GqVfhi",
        "colab_type": "text"
      },
      "source": [
        "# Pre-trained Word Embeddings and RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dRBQ88DscTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 3773\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-CAqud9zl4Z",
        "colab_type": "text"
      },
      "source": [
        "## IMDB Reviews Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS7TAPJruzr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDDzCMY3u-46",
        "colab_type": "code",
        "outputId": "f0743cc8-1b89-4308-b743-81fc0dccfff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Number of training examples: {}\".format(len(train_data)))\n",
        "print(\"Number of testing examples: {}\".format(len(test_data)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ572Bd_wC6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49SaxIn60D2B",
        "colab_type": "text"
      },
      "source": [
        "## Training, Validation and Testing Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM5CtAGe2eho",
        "colab_type": "code",
        "outputId": "83058868-c112-4a8d-87a0-dc0607fdf115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(\n",
        "    random_state=random.seed(SEED),\n",
        "    split_ratio=0.8\n",
        ")\n",
        "\n",
        "print(\"Number of training examples: {}\".format(len(train_data)))\n",
        "print(\"Number of validation examples: {}\".format(len(valid_data)))\n",
        "print(\"Number of testing examples: {}\".format(len(test_data)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C74UYys0SSG",
        "colab_type": "text"
      },
      "source": [
        "## Vocabulary and Pre-Trained Embedding (Glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nul-rT84zAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 8185\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                 max_size=MAX_VOCAB_SIZE,\n",
        "                 vectors=\"glove.6B.100d\",\n",
        "                 unk_init=torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXyHKPd054Am",
        "colab_type": "code",
        "outputId": "e14bfa81-3feb-417f-be68-31ff8c9c9c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Unique tokens in TEXT vocabulary: {}\".format(len(TEXT.vocab)))\n",
        "print(\"Unique tokens in LABEL vocabulary: {}\".format(len(LABEL.vocab)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 8187\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAb8f32B6Jcp",
        "colab_type": "code",
        "outputId": "e9f78a32-7fad-4592-b31f-76cdb41198f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 232678), (',', 220840), ('.', 188920), ('and', 125362), ('a', 125266), ('of', 115884), ('to', 107654), ('is', 87196), ('in', 70206), ('I', 62349), ('it', 61298), ('that', 56438), ('\"', 50419), (\"'s\", 49667), ('this', 48419), ('-', 41945), ('/><br', 41022), ('was', 40196), ('as', 35006), ('with', 34063)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA--x2i66ejW",
        "colab_type": "code",
        "outputId": "153b8a84-01a4-47bf-bca3-2fe49068f7d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cCa8T_t8Tf9",
        "colab_type": "code",
        "outputId": "ffa6244d-a3cd-4c42-ed09-d34984c4e0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f66299dd378>, {'pos': 0, 'neg': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVtV1PKW9nLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRwgbjPi0zJa",
        "colab_type": "text"
      },
      "source": [
        "## Sequence Processing with RNNs using LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIg0PitTn1or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim,\n",
        "                 hidden_dim, output_dim,\n",
        "                 n_layers, bidirectional):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, sequences):\n",
        "\n",
        "        # sequences: (max sequences length, batch size)\n",
        "        seq_embeddings = self.embedding(sequences)\n",
        "\n",
        "        # seq_embeddings: (max sequences length, batch size, embedding dim)\n",
        "        seq_hidden, (hidden, cell) = self.rnn(seq_embeddings)\n",
        "\n",
        "        # hidden: (num_layers * num_directions, batch size, hidden dim)\n",
        "        hidden_concat = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "\n",
        "        # hidden_concat: (batch size, num_directions * hidden dim)\n",
        "        output = self.fc(hidden_concat)\n",
        "\n",
        "        # output: (batch size, 1) -> vector\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FFmffa4nCjOf",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6yzD7xqCKPk",
        "colab_type": "text"
      },
      "source": [
        "## Model 1: 1 bidrectional layer, no pre-trained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHQT54qZNjco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "model_v1 = RNN(INPUT_DIM,\n",
        "               EMBEDDING_DIM,\n",
        "               HIDDEN_DIM,\n",
        "               OUTPUT_DIM,\n",
        "               N_LAYERS,\n",
        "               BIDIRECTIONAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdj7irbQEeur",
        "colab_type": "code",
        "outputId": "56f7fe96-2229-4c2a-f7bd-4a326e183d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"The model has {:,} trainable parameters\".format(count_parameters(model_v1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,552,397 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hydzoi6UC9fN",
        "colab_type": "text"
      },
      "source": [
        "## Model 2: 1 bidirectional layer, pre-trained embeddings (Glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQsJnV45DPo0",
        "colab_type": "code",
        "outputId": "c732e401-b5ca-4458-c477-299d803b867c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "model_v2 = RNN(INPUT_DIM,\n",
        "               EMBEDDING_DIM,\n",
        "               HIDDEN_DIM,\n",
        "               OUTPUT_DIM,\n",
        "               N_LAYERS,\n",
        "               BIDIRECTIONAL)\n",
        "\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model_v2.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1285, -0.7403, -0.7101,  ...,  0.0324, -0.4687,  1.6241],\n",
              "        [ 0.3661, -0.2995, -0.1835,  ..., -2.0702,  1.9870,  1.3561],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.2122, -0.5872,  0.2765,  ...,  0.0076, -0.2042,  0.2265],\n",
              "        [-0.5347,  0.2205, -0.5386,  ..., -0.3264,  1.0983, -0.1159],\n",
              "        [-0.4323, -0.3820, -0.1995,  ..., -0.4230,  0.1340, -0.1766]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f7afb1ca-85ef-444a-a9f4-f0a39f2d991e",
        "id": "p33lbO2rR2OT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"The model has {:,} trainable parameters\".format(count_parameters(model_v2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,552,397 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJoMHSFIO0wZ",
        "colab_type": "text"
      },
      "source": [
        "## Model 3: 1 bidirectional layer, Glove, frozen embeddings layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9eb16162-6a39-4535-cb70-e829b6842b8e",
        "id": "NETuJjnnOZFj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "model_v3 = RNN(INPUT_DIM,\n",
        "               EMBEDDING_DIM,\n",
        "               HIDDEN_DIM,\n",
        "               OUTPUT_DIM,\n",
        "               N_LAYERS,\n",
        "               BIDIRECTIONAL)\n",
        "\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model_v3.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1285, -0.7403, -0.7101,  ...,  0.0324, -0.4687,  1.6241],\n",
              "        [ 0.3661, -0.2995, -0.1835,  ..., -2.0702,  1.9870,  1.3561],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.2122, -0.5872,  0.2765,  ...,  0.0076, -0.2042,  0.2265],\n",
              "        [-0.5347,  0.2205, -0.5386,  ..., -0.3264,  1.0983, -0.1159],\n",
              "        [-0.4323, -0.3820, -0.1995,  ..., -0.4230,  0.1340, -0.1766]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "85806906-2ea5-444a-ebec-a18d1f9970be",
        "id": "7N6qbhUnOkS9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "embedding_params = sum(p.numel() for p in model_v3.embedding.parameters() if p.requires_grad)\n",
        "\n",
        "for parameter in model_v3.embedding.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "print(\"The model's embedding layer has {:,} parameters\".format(embedding_params))\n",
        "print(\"The model has {:,} trainable parameters\".format(count_parameters(model_v3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model's embedding layer has 818,700 parameters\n",
            "The model has 733,697 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66zy-RoOe34V",
        "colab_type": "text"
      },
      "source": [
        "## Model 4: 2 bidirectional LSTM layers, pre-trained embeddings (Glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d5fccf72-68c4-4c9e-affb-71ed0e36b77b",
        "id": "prxPF3QefIGJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "model_v4 = RNN(INPUT_DIM,\n",
        "               EMBEDDING_DIM,\n",
        "               HIDDEN_DIM,\n",
        "               OUTPUT_DIM,\n",
        "               N_LAYERS,\n",
        "               BIDIRECTIONAL)\n",
        "\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model_v4.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1285, -0.7403, -0.7101,  ...,  0.0324, -0.4687,  1.6241],\n",
              "        [ 0.3661, -0.2995, -0.1835,  ..., -2.0702,  1.9870,  1.3561],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.2122, -0.5872,  0.2765,  ...,  0.0076, -0.2042,  0.2265],\n",
              "        [-0.5347,  0.2205, -0.5386,  ..., -0.3264,  1.0983, -0.1159],\n",
              "        [-0.4323, -0.3820, -0.1995,  ..., -0.4230,  0.1340, -0.1766]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9ea7cb49-2b76-4762-e206-9bccabd6a735",
        "id": "l2MWlRQkfpK-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"The model has {:,} trainable parameters\".format(count_parameters(model_v4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,129,357 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUoHqRIkcoi1",
        "colab_type": "text"
      },
      "source": [
        "## Training the RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1cy7BnqQ2Vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XypWXAsUddjg",
        "colab_type": "text"
      },
      "source": [
        "### Loss function: Binary Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7d-2vJsRTXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model_v1 = model_v1.to(device)\n",
        "model_v2 = model_v2.to(device)\n",
        "model_v3 = model_v3.to(device)\n",
        "model_v4 = model_v4.to(device)\n",
        "\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVYnqOIwcwZc",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpD93CtMU7fP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Precit y = 1 if sigmoid(output) >= 0.5 (positive review)\n",
        "    # Precit y = 0 if sigmoid(output) <  0.5 (negative review)\n",
        "    predictions = torch.round(torch.sigmoid(outputs))\n",
        "    correct = (predictions == labels).float()\n",
        "    return correct.sum() / len(correct)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvDC4F7xc2Cm",
        "colab_type": "text"
      },
      "source": [
        "### Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMPz5h-knW0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, cruterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(batch.text).squeeze(1)\n",
        "\n",
        "        loss = criterion(outputs, batch.label)\n",
        "\n",
        "        acc = accuracy(outputs, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMg0s4ZAc8eh",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naN15Mx0joaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            outputs = model(batch.text).squeeze(1)\n",
        "\n",
        "            loss = criterion(outputs, batch.label)\n",
        "\n",
        "            acc = accuracy(outputs, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3k2iNZodJYU",
        "colab_type": "text"
      },
      "source": [
        "### Epoch Timer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_sbes3gkmsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins, elapsed_secs = divmod(int(elapsed_time), 60)\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c-1mcrBTcQn",
        "colab_type": "text"
      },
      "source": [
        "### Training-Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMW-YJcsTkJJ",
        "colab": {}
      },
      "source": [
        "def train_evaluate(model, optimizer, criterion, n_epochs):\n",
        "\n",
        "    metrics = {\n",
        "        \"train_accu\": [],\n",
        "        \"train_loss\": [],\n",
        "        \"valid_accu\": [],\n",
        "        \"valid_loss\": [],\n",
        "    }\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "        print(\"Epoch: {:02} | Epoch Time: {}m {}s\".format(epoch+1, epoch_mins, epoch_secs))\n",
        "        print(\"\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%\".format(train_loss, train_acc*100))\n",
        "        print(\"\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%\".format(valid_loss, valid_acc*100))\n",
        "\n",
        "        metrics[\"train_accu\"].append(train_accu)\n",
        "        metrics[\"train_loss\"].append(train_loss)\n",
        "        metrics[\"valid_accu\"].append(valid_accu)\n",
        "        metrics[\"valid_loss\"].append(valid_loss)\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQexpTAlSEEW",
        "colab_type": "text"
      },
      "source": [
        "## Model 1 - Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BasK5vKlEp3",
        "colab_type": "code",
        "outputId": "879dccbf-6354-4fb2-a4fc-2c7b760e2690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "optimizer_v1 = optim.Adam(model_v1.parameters())\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model_v1, train_iterator, optimizer_v1, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model_v1, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(\"Epoch: {:02} | Epoch Time: {}m {}s\".format(epoch+1, epoch_mins, epoch_secs))\n",
        "    print(\"\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%\".format(train_loss, train_acc*100))\n",
        "    print(\"\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%\".format(valid_loss, valid_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.613 | Train Acc: 66.56%\n",
            "\t Val. Loss: 0.628 |  Val. Acc: 65.41%\n",
            "Epoch: 02 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.617 | Train Acc: 65.90%\n",
            "\t Val. Loss: 0.671 |  Val. Acc: 60.40%\n",
            "Epoch: 03 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.592 | Train Acc: 68.70%\n",
            "\t Val. Loss: 0.459 |  Val. Acc: 80.06%\n",
            "Epoch: 04 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.376 | Train Acc: 83.97%\n",
            "\t Val. Loss: 0.338 |  Val. Acc: 85.88%\n",
            "Epoch: 05 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.274 | Train Acc: 88.91%\n",
            "\t Val. Loss: 0.346 |  Val. Acc: 85.46%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X0OffS8rK5Q",
        "colab_type": "code",
        "outputId": "da1833e1-128f-4917-8451-fa972029ed94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_acc = evaluate(model_v1, test_iterator, criterion)\n",
        "\n",
        "print(\"Test Loss: {:.3f} |  Test Acc: {:.2f}%\".format(test_loss, test_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.406 |  Test Acc: 82.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LkD-LjqScr-",
        "colab_type": "text"
      },
      "source": [
        "## Model 2 - Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d50dc22b-1d42-4d80-ee2d-c1704dce36e5",
        "id": "h1mOp6u_SRKc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "optimizer_v2 = optim.Adam(model_v2.parameters())\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model_v2, train_iterator, optimizer_v2, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model_v2, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(\"Epoch: {:02} | Epoch Time: {}m {}s\".format(epoch+1, epoch_mins, epoch_secs))\n",
        "    print(\"\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%\".format(train_loss, train_acc*100))\n",
        "    print(\"\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%\".format(valid_loss, valid_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 48s\n",
            "\tTrain Loss: 0.681 | Train Acc: 56.62%\n",
            "\t Val. Loss: 0.599 |  Val. Acc: 69.48%\n",
            "Epoch: 02 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.651 | Train Acc: 61.37%\n",
            "\t Val. Loss: 0.599 |  Val. Acc: 65.96%\n",
            "Epoch: 03 | Epoch Time: 0m 50s\n",
            "\tTrain Loss: 0.361 | Train Acc: 84.92%\n",
            "\t Val. Loss: 0.346 |  Val. Acc: 86.33%\n",
            "Epoch: 04 | Epoch Time: 0m 50s\n",
            "\tTrain Loss: 0.253 | Train Acc: 90.15%\n",
            "\t Val. Loss: 0.283 |  Val. Acc: 88.15%\n",
            "Epoch: 05 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.201 | Train Acc: 92.47%\n",
            "\t Val. Loss: 0.273 |  Val. Acc: 88.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2c7e25c8-5977-4bf7-c3bf-43208f5623ab",
        "id": "wE9QlMHpSUPs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_acc = evaluate(model_v2, test_iterator, criterion)\n",
        "\n",
        "print(\"Test Loss: {:.3f} |  Test Acc: {:.2f}%\".format(test_loss, test_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.284 |  Test Acc: 88.20%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGCs2J8jmAN9",
        "colab_type": "text"
      },
      "source": [
        "## Model 3 - Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b8c2d6f4-5224-4874-d5c0-f53958dca49b",
        "id": "ftFYRCqImH0E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "optimizer_v3 = optim.Adam([p for p in model_v3.parameters() if p.requires_grad])\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model_v3, train_iterator, optimizer_v3, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model_v3, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(\"Epoch: {:02} | Epoch Time: {}m {}s\".format(epoch+1, epoch_mins, epoch_secs))\n",
        "    print(\"\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%\".format(train_loss, train_acc*100))\n",
        "    print(\"\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%\".format(valid_loss, valid_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.676 | Train Acc: 56.76%\n",
            "\t Val. Loss: 0.661 |  Val. Acc: 56.33%\n",
            "Epoch: 02 | Epoch Time: 0m 48s\n",
            "\tTrain Loss: 0.684 | Train Acc: 55.63%\n",
            "\t Val. Loss: 0.671 |  Val. Acc: 57.89%\n",
            "Epoch: 03 | Epoch Time: 0m 48s\n",
            "\tTrain Loss: 0.573 | Train Acc: 69.41%\n",
            "\t Val. Loss: 0.446 |  Val. Acc: 79.43%\n",
            "Epoch: 04 | Epoch Time: 0m 48s\n",
            "\tTrain Loss: 0.410 | Train Acc: 81.84%\n",
            "\t Val. Loss: 0.411 |  Val. Acc: 81.19%\n",
            "Epoch: 05 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.368 | Train Acc: 84.01%\n",
            "\t Val. Loss: 0.373 |  Val. Acc: 84.36%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cb6d361d-c0b9-43c6-9557-4454ba22d32b",
        "id": "ZTH17sUvmLM_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_acc = evaluate(model_v3, test_iterator, criterion)\n",
        "\n",
        "print(\"Test Loss: {:.3f} |  Test Acc: {:.2f}%\".format(test_loss, test_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.402 |  Test Acc: 81.80%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXumc-QMmMtt",
        "colab_type": "text"
      },
      "source": [
        "## Model 4 - Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f329ada9-5940-476a-da99-ae3cbb3d46b3",
        "id": "Tfc82VSFmS-g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "optimizer_v4 = optim.Adam(model_v4.parameters())\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model_v4, train_iterator, optimizer_v4, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model_v4, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(\"Epoch: {:02} | Epoch Time: {}m {}s\".format(epoch+1, epoch_mins, epoch_secs))\n",
        "    print(\"\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%\".format(train_loss, train_acc*100))\n",
        "    print(\"\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%\".format(valid_loss, valid_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 2m 3s\n",
            "\tTrain Loss: 0.680 | Train Acc: 57.48%\n",
            "\t Val. Loss: 0.663 |  Val. Acc: 62.99%\n",
            "Epoch: 02 | Epoch Time: 2m 9s\n",
            "\tTrain Loss: 0.647 | Train Acc: 62.51%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 55.72%\n",
            "Epoch: 03 | Epoch Time: 2m 8s\n",
            "\tTrain Loss: 0.590 | Train Acc: 67.35%\n",
            "\t Val. Loss: 0.380 |  Val. Acc: 84.08%\n",
            "Epoch: 04 | Epoch Time: 2m 8s\n",
            "\tTrain Loss: 0.312 | Train Acc: 87.06%\n",
            "\t Val. Loss: 0.286 |  Val. Acc: 88.41%\n",
            "Epoch: 05 | Epoch Time: 2m 7s\n",
            "\tTrain Loss: 0.229 | Train Acc: 90.76%\n",
            "\t Val. Loss: 0.280 |  Val. Acc: 89.22%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "13007c5d-aabd-40a1-fa73-0c71b580854e",
        "id": "6jaF5JQRmV__",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_acc = evaluate(model_v4, test_iterator, criterion)\n",
        "print(\"Test Loss: {:.3f} |  Test Acc: {:.2f}%\".format(test_loss, test_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.301 |  Test Acc: 87.97%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}