{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03b_NLP_and_recurrent_neural_networks.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN7C0v0DBlq4xtFRcfrYd6o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/introNLP/blob/master/03b_NLP_and_recurrent_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdoE59GqVfhi",
        "colab_type": "text"
      },
      "source": [
        "# Pre-trained Word Embeddings and RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dRBQ88DscTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 3773\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS7TAPJruzr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDDzCMY3u-46",
        "colab_type": "code",
        "outputId": "0c4297db-39be-4fce-e955-57c32efd50dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Number of training examples: {}\".format(len(train_data)))\n",
        "print(\"Number of testing examples: {}\".format(len(test_data)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ572Bd_wC6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM5CtAGe2eho",
        "colab_type": "code",
        "outputId": "133c639b-d083-4be3-dbe6-29030b397ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(\n",
        "    random_state=random.seed(SEED),\n",
        "    split_ratio=0.8\n",
        ")\n",
        "\n",
        "print(\"Number of training examples: {}\".format(len(train_data)))\n",
        "print(\"Number of validation examples: {}\".format(len(valid_data)))\n",
        "print(\"Number of testing examples: {}\".format(len(test_data)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nul-rT84zAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 8185\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                 max_size=MAX_VOCAB_SIZE,\n",
        "                 vectors=\"glove.6B.100d\",\n",
        "                 unk_init=torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXyHKPd054Am",
        "colab_type": "code",
        "outputId": "1bd2c666-0b6f-49cb-abe2-d40036291ae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Unique tokens in TEXT vocabulary: {}\".format(len(TEXT.vocab)))\n",
        "print(\"Unique tokens in LABEL vocabulary: {}\".format(len(LABEL.vocab)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 8187\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAb8f32B6Jcp",
        "colab_type": "code",
        "outputId": "9f59dd90-f304-44a0-c8c3-2b552fb75994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 232678), (',', 220840), ('.', 188920), ('and', 125362), ('a', 125266), ('of', 115884), ('to', 107654), ('is', 87196), ('in', 70206), ('I', 62349), ('it', 61298), ('that', 56438), ('\"', 50419), (\"'s\", 49667), ('this', 48419), ('-', 41945), ('/><br', 41022), ('was', 40196), ('as', 35006), ('with', 34063)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA--x2i66ejW",
        "colab_type": "code",
        "outputId": "d8cdaab7-c020-4b0b-c985-ffad511fefe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cCa8T_t8Tf9",
        "colab_type": "code",
        "outputId": "e1872dac-252e-4a59-eff1-ad12a9d5a69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fa312e5d378>, {'pos': 0, 'neg': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVtV1PKW9nLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIg0PitTn1or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim,\n",
        "                 hidden_dim, output_dim,\n",
        "                 n_layers, bidirectional):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, sequences):\n",
        "\n",
        "        # sequences: (max sequences length, batch size)\n",
        "        seq_embeddings = self.embedding(sequences)\n",
        "\n",
        "        # seq_embeddings: (max sequences length, batch size, embedding dim)\n",
        "        seq_hidden, (hidden, cell) = self.rnn(seq_embeddings)\n",
        "\n",
        "        # hidden: (num_layers * num_directions, batch size, hidden dim)\n",
        "        hidden_concat = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "\n",
        "        # hidden_concat: (batch size, num_directions * hidden dim)\n",
        "        output = self.fc(hidden_concat)\n",
        "\n",
        "        # output: (batch size, 1) -> vector\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FFmffa4nCjOf",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6yzD7xqCKPk",
        "colab_type": "text"
      },
      "source": [
        "## Model 1 - 1 bidrectional layer, no pre-trained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHQT54qZNjco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "model_v1 = RNN(INPUT_DIM,\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM,\n",
        "            OUTPUT_DIM,\n",
        "            N_LAYERS,\n",
        "            BIDIRECTIONAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdj7irbQEeur",
        "colab_type": "code",
        "outputId": "d00ea661-d765-4180-ac3c-9cdeca13650a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"The model has {:,} trainable parameters\".format(count_parameters(model_v1)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,552,397 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hydzoi6UC9fN",
        "colab_type": "text"
      },
      "source": [
        "## Model 2 - 1 bidirectional layer, pre-trained embeddings (Glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQsJnV45DPo0",
        "colab_type": "code",
        "outputId": "6c76a072-da49-43e0-826a-e3027ab31d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "model_v2 = RNN(INPUT_DIM,\n",
        "               EMBEDDING_DIM,\n",
        "               HIDDEN_DIM,\n",
        "               OUTPUT_DIM,\n",
        "               N_LAYERS,\n",
        "               BIDIRECTIONAL)\n",
        "\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model_v2.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1285, -0.7403, -0.7101,  ...,  0.0324, -0.4687,  1.6241],\n",
              "        [ 0.3661, -0.2995, -0.1835,  ..., -2.0702,  1.9870,  1.3561],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.2122, -0.5872,  0.2765,  ...,  0.0076, -0.2042,  0.2265],\n",
              "        [-0.5347,  0.2205, -0.5386,  ..., -0.3264,  1.0983, -0.1159],\n",
              "        [-0.4323, -0.3820, -0.1995,  ..., -0.4230,  0.1340, -0.1766]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5d3b257f-da68-47c1-bd3d-6cc29cc07929",
        "id": "p33lbO2rR2OT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"The model has {:,} trainable parameters\".format(count_parameters(model_v2)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,552,397 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJoMHSFIO0wZ",
        "colab_type": "text"
      },
      "source": [
        "## Model 3 - 1 bidirectional layer, Glove, frozen embeddings layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6515f6ec-8c75-4e3e-dd7c-30eaa089153f",
        "id": "NETuJjnnOZFj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "model_v3 = RNN(INPUT_DIM,\n",
        "               EMBEDDING_DIM,\n",
        "               HIDDEN_DIM,\n",
        "               OUTPUT_DIM,\n",
        "               N_LAYERS,\n",
        "               BIDIRECTIONAL)\n",
        "\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model_v3.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1285, -0.7403, -0.7101,  ...,  0.0324, -0.4687,  1.6241],\n",
              "        [ 0.3661, -0.2995, -0.1835,  ..., -2.0702,  1.9870,  1.3561],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.2122, -0.5872,  0.2765,  ...,  0.0076, -0.2042,  0.2265],\n",
              "        [-0.5347,  0.2205, -0.5386,  ..., -0.3264,  1.0983, -0.1159],\n",
              "        [-0.4323, -0.3820, -0.1995,  ..., -0.4230,  0.1340, -0.1766]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "98a9a72f-1e20-4caf-a230-1c8282bf8822",
        "id": "7N6qbhUnOkS9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "embedding_params = sum(p.numel() for p in model_v3.embedding.parameters() if p.requires_grad)\n",
        "\n",
        "for parameter in model_v3.embedding.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "print(\"The model's embedding layer has {:,} parameters\".format(embedding_params))\n",
        "print(\"The model has {:,} trainable parameters\".format(count_parameters(model_v3)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model's embedding layer has 818,700 parameters\n",
            "The model has 733,697 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1cy7BnqQ2Vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer_v1 = optim.Adam(model_v1.parameters())\n",
        "\n",
        "optimizer_v2 = optim.Adam(model_v2.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7d-2vJsRTXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model_v1 = model_v1.to(device)\n",
        "model_v2 = model_v2.to(device)\n",
        "\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpD93CtMU7fP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Precit y = 1 if sigmoid(output) >= 0.5 (positive review)\n",
        "    # Precit y = 0 if sigmoid(output) <  0.5 (negative review)\n",
        "    predictions = torch.round(torch.sigmoid(outputs))\n",
        "    correct = (predictions == labels).float()\n",
        "    return correct.sum() / len(correct)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMPz5h-knW0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, cruterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(batch.text).squeeze(1)\n",
        "\n",
        "        loss = criterion(outputs, batch.label)\n",
        "\n",
        "        acc = accuracy(outputs, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naN15Mx0joaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            outputs = model(batch.text).squeeze(1)\n",
        "\n",
        "            loss = criterion(outputs, batch.label)\n",
        "\n",
        "            acc = accuracy(outputs, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_sbes3gkmsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins, elapsed_secs = divmod(int(elapsed_time), 60)\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQexpTAlSEEW",
        "colab_type": "text"
      },
      "source": [
        "## Model 1 - Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BasK5vKlEp3",
        "colab_type": "code",
        "outputId": "92cb211b-4e6a-47a6-9ba3-c2f901203678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model_v1, train_iterator, optimizer_v1, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model_v1, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(\"Epoch: {:02} | Epoch Time: {}m {}s\".format(epoch+1, epoch_mins, epoch_secs))\n",
        "    print(\"\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%\".format(train_loss, train_acc*100))\n",
        "    print(\"\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%\".format(valid_loss, valid_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 45s\n",
            "\tTrain Loss: 0.681 | Train Acc: 56.12%\n",
            "\t Val. Loss: 0.657 |  Val. Acc: 61.79%\n",
            "Epoch: 02 | Epoch Time: 0m 46s\n",
            "\tTrain Loss: 0.640 | Train Acc: 63.49%\n",
            "\t Val. Loss: 0.661 |  Val. Acc: 61.00%\n",
            "Epoch: 03 | Epoch Time: 0m 50s\n",
            "\tTrain Loss: 0.598 | Train Acc: 68.43%\n",
            "\t Val. Loss: 0.563 |  Val. Acc: 72.49%\n",
            "Epoch: 04 | Epoch Time: 0m 50s\n",
            "\tTrain Loss: 0.533 | Train Acc: 74.36%\n",
            "\t Val. Loss: 0.563 |  Val. Acc: 71.84%\n",
            "Epoch: 05 | Epoch Time: 0m 51s\n",
            "\tTrain Loss: 0.588 | Train Acc: 68.16%\n",
            "\t Val. Loss: 0.585 |  Val. Acc: 70.51%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X0OffS8rK5Q",
        "colab_type": "code",
        "outputId": "4b16bfd1-ed91-44f8-a0ef-1ff7323e2508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_acc = evaluate(model_v1, test_iterator, criterion)\n",
        "\n",
        "print(\"Test Loss: {:.3f} |  Test Acc: {:.2f}%\".format(test_loss, test_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.590 |  Test Acc: 69.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LkD-LjqScr-",
        "colab_type": "text"
      },
      "source": [
        "## Model 2 - Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "dde3c983-eb15-49e6-c874-87dc780530f5",
        "id": "h1mOp6u_SRKc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model_v2, train_iterator, optimizer_v2, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model_v2, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(\"Epoch: {:02} | Epoch Time: {}m {}s\".format(epoch+1, epoch_mins, epoch_secs))\n",
        "    print(\"\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%\".format(train_loss, train_acc*100))\n",
        "    print(\"\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%\".format(valid_loss, valid_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 48s\n",
            "\tTrain Loss: 0.653 | Train Acc: 60.56%\n",
            "\t Val. Loss: 0.614 |  Val. Acc: 65.39%\n",
            "Epoch: 02 | Epoch Time: 0m 50s\n",
            "\tTrain Loss: 0.575 | Train Acc: 69.20%\n",
            "\t Val. Loss: 0.368 |  Val. Acc: 84.14%\n",
            "Epoch: 03 | Epoch Time: 0m 50s\n",
            "\tTrain Loss: 0.308 | Train Acc: 87.23%\n",
            "\t Val. Loss: 0.279 |  Val. Acc: 88.59%\n",
            "Epoch: 04 | Epoch Time: 0m 50s\n",
            "\tTrain Loss: 0.230 | Train Acc: 90.88%\n",
            "\t Val. Loss: 0.270 |  Val. Acc: 89.58%\n",
            "Epoch: 05 | Epoch Time: 0m 51s\n",
            "\tTrain Loss: 0.179 | Train Acc: 93.09%\n",
            "\t Val. Loss: 0.281 |  Val. Acc: 88.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "177a380a-562a-4841-9dca-4e42c6d1504a",
        "id": "wE9QlMHpSUPs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_acc = evaluate(model_v2, test_iterator, criterion)\n",
        "\n",
        "print(\"Test Loss: {:.3f} |  Test Acc: {:.2f}%\".format(test_loss, test_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.312 |  Test Acc: 87.83%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}