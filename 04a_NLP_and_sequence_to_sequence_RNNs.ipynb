{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04a_NLP_and_sequence-to-sequence_RNNs.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPnLFWKX8Y69NmrPSsLbw/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/introNLP/blob/master/04a_NLP_and_sequence_to_sequence_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12TvrvBulJba",
        "colab_type": "text"
      },
      "source": [
        "# NLP and Sequence-to-Sequence RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7C_h_GLDTbK",
        "colab_type": "code",
        "outputId": "96c1109d-d8ae-4d4c-ac90-117600315de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "!wget https://www.manythings.org/anki/spa-eng.zip\n",
        "!unzip spa-eng.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-15 14:51:32--  https://www.manythings.org/anki/spa-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 2606:4700:3033::6818:6dc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4767708 (4.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "\rspa-eng.zip           0%[                    ]       0  --.-KB/s               \rspa-eng.zip          36%[======>             ]   1.64M  7.50MB/s               \rspa-eng.zip         100%[===================>]   4.55M  17.3MB/s    in 0.3s    \n",
            "\n",
            "2020-02-15 14:51:33 (17.3 MB/s) - ‘spa-eng.zip’ saved [4767708/4767708]\n",
            "\n",
            "Archive:  spa-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: spa.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-va0tQ1eYb0",
        "colab_type": "code",
        "outputId": "5b312ca5-a841-479e-8761-4dade184b53f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download es"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting es_core_news_sm==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.1.0/es_core_news_sm-2.1.0.tar.gz (11.1MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1MB 17.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: es-core-news-sm\n",
            "  Building wheel for es-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-sm: filename=es_core_news_sm-2.1.0-cp36-none-any.whl size=11111556 sha256=312d43c959c0cd8fe37d426cdbf3e09fa79a39b982be8c9badf650e03a6a3b30\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f19z7qz_/wheels/cc/ee/c4/68922955901918a9aaa82e828d4f7ee1ccfc861285277e79b7\n",
            "Successfully built es-core-news-sm\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/es_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/es\n",
            "You can now load the model via spacy.load('es')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejo5g5kBECxP",
        "colab_type": "code",
        "outputId": "b613f4d0-36d1-4b10-f35e-4440c888777c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import TranslationDataset\n",
        "from torchtext import data\n",
        "\n",
        "import spacy\n",
        "\n",
        "from io import open\n",
        "\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import os\n",
        "\n",
        "print(\"Spacy version:\", spacy.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spacy version: 2.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64vE5FSE2tgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        char for char in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(char) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_kg0w9K5XHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readPairs(pathToFile, slang, tlang):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    f = open(pathToFile, encoding='utf-8')\n",
        "    lines = f.read().strip().split('\\n')\n",
        "\n",
        "    pairs = [[normalizeString(s) for s in line.split('\\t')[:2]] for line in lines]\n",
        "\n",
        "    return pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV0nAsYq8ClC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am\", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[0].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRDq95CW_ll8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepareData(pathToFile, slang, tlang):\n",
        "    pairs = readPairs(pathToFile, slang, tlang)\n",
        "    print(\"Read {} sentence pairs\".format(len(pairs)))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to {} sentence pairs\".format(len(pairs)))\n",
        "    return pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFs44kLn_INN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def datasetIndexes(pairs, train=0.8, val=0.1):\n",
        "    num_examples = len(pairs)\n",
        "    indexes = list(range(num_examples))\n",
        "    last_train_idx = round(train*num_examples)\n",
        "    last_valid_idx = last_train_idx + round(val*num_examples)\n",
        "    random.shuffle(indexes)\n",
        "    train_idxs = indexes[:last_train_idx]\n",
        "    val_idxs = indexes[last_train_idx:last_valid_idx]\n",
        "    test_idxs = indexes[last_valid_idx:]\n",
        "    return train_idxs, val_idxs, test_idxs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H19pHY6QPyF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SpanishDataset(TranslationDataset):\n",
        "    \"\"\"English to Spanish Dataset\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def splits(cls, exts, fields, root='.data/',\n",
        "               train='train', validation='val', test='test', **kwargs):\n",
        "        \n",
        "        if 'path' not in kwargs:\n",
        "            expected_folder = os.path.join(root, cls.name)\n",
        "            path = expected_folder if os.path.exists(expected_folder) else None\n",
        "        else:\n",
        "            path = kwargs['path']\n",
        "            del kwargs['path']\n",
        "        \n",
        "        return super(SpanishDataset, cls).splits(\n",
        "            exts, fields, path, root, train, validation, test, **kwargs\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKp8BQP6DX6c",
        "colab_type": "code",
        "outputId": "a7fc7cec-566b-4439-d02f-7f69f7c456b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "pairs = prepareData('spa.txt', 'eng', 'spa')\n",
        "train_idxs, val_idxs, test_idxs = datasetIndexes(pairs)\n",
        "print(\"{} {} {}\".format(len(train_idxs), len(val_idxs), len(test_idxs) ))\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 123335 sentence pairs\n",
            "Trimmed to 7588 sentence pairs\n",
            "6070 759 759\n",
            "['i am happy to see you again .', 'estoy feliz de verte otra vez .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf-RZx3YGSDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('train.en', 'w') as slang_file, open('train.es', 'w') as tlang_file:\n",
        "    for i in train_idxs:\n",
        "        slang_file.write(pairs[i][0] + '\\n')\n",
        "        tlang_file.write(pairs[i][1] + '\\n')\n",
        "\n",
        "with open('val.en', 'w') as slang_file, open('val.es', 'w') as tlang_file:\n",
        "    for i in val_idxs:\n",
        "        slang_file.write(pairs[i][0] + '\\n')\n",
        "        tlang_file.write(pairs[i][1] + '\\n')\n",
        "\n",
        "with open('test.en', 'w') as slang_file, open('test.es', 'w') as tlang_file:\n",
        "    for i in test_idxs:\n",
        "        slang_file.write(pairs[i][0] + '\\n')\n",
        "        tlang_file.write(pairs[i][1] + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y03SbEQ1X54e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "spacy_es = spacy.load('es')\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "def tokenize_es(text):\n",
        "    \"\"\"\n",
        "    Tokenizes Spanish text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [token.text for token in spacy_es.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [token.text for token in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G1OJirugl6j",
        "colab_type": "code",
        "outputId": "c37a0cd5-0f6f-4d97-85f6-4f90e672948c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pwd\n",
        "!ls -l"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "total 23068\n",
            "-rw-r--r-- 1 root root     1441 Jan 11 23:49 _about.txt\n",
            "drwxr-xr-x 1 root root     4096 Feb  5 18:37 sample_data\n",
            "-rw-r--r-- 1 root root  4767708 Jan 11 14:49 spa-eng.zip\n",
            "-rw-r--r-- 1 root root 18432706 Jan 11 23:49 spa.txt\n",
            "-rw-r--r-- 1 root root    19187 Feb 15 14:52 test.en\n",
            "-rw-r--r-- 1 root root    20265 Feb 15 14:52 test.es\n",
            "-rw-r--r-- 1 root root   155117 Feb 15 14:52 train.en\n",
            "-rw-r--r-- 1 root root   164106 Feb 15 14:52 train.es\n",
            "-rw-r--r-- 1 root root    19405 Feb 15 14:52 val.en\n",
            "-rw-r--r-- 1 root root    20540 Feb 15 14:52 val.es\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-37Cb1XYY-08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC = data.Field(tokenize=tokenize_en, init_token='<SOS>', eos_token='<EOS>', lower=True)\n",
        "TRG = data.Field(tokenize=tokenize_es, init_token='<SOS>', eos_token='<EOS>', lower=True)\n",
        "\n",
        "train_data, valid_data, test_data = SpanishDataset.splits(\n",
        "    path='',\n",
        "    exts=('.en', '.es'),\n",
        "    fields=(SRC, TRG)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYPDAg7YiSu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=5)\n",
        "TRG.build_vocab(train_data, min_freq=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVGpH1PiaLpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QIyVoSKcIfH",
        "colab_type": "code",
        "outputId": "7056a07e-47cb-460f-a6fd-d7f568a8ea9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(valid_data))\n",
        "print(len(test_data))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6070\n",
            "759\n",
            "759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlMdtj01WXIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67913a22-ef83-4dca-b5ec-6d66b0b5d7e6"
      },
      "source": [
        "SRC.vocab.itos[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '<SOS>', '<EOS>', '.', 'i', 'm', 're', 'you', 'he']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7DsRjXshe0B",
        "colab_type": "code",
        "outputId": "2fc23654-c3ee-4a7a-e82e-dd5d48d48bbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch = next(iter(train_iterator))\n",
        "\n",
        "src_example = batch.src[:, 0]\n",
        "src = ' '.join(map(lambda i: SRC.vocab.itos[i], src_example))\n",
        "trg_example = batch.trg[:, 0]\n",
        "trg = ' '.join(map(lambda i: TRG.vocab.itos[i], trg_example))\n",
        "\n",
        "print(\"English sentence:\", src)\n",
        "print(\"Spanish sentence:\", trg)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English sentence: <SOS> i m taller than him . <EOS> <pad> <pad> <pad>\n",
            "Spanish sentence: <SOS> soy mas alto que el . <EOS> <pad> <pad> <pad>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp2GwmBkcOsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "58d59ba3-73b4-4cf0-bf0e-8e14fb1d97c8"
      },
      "source": [
        "SRC.vocab.freqs.most_common(20)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 5988),\n",
              " ('i', 2793),\n",
              " ('m', 2192),\n",
              " ('re', 1433),\n",
              " ('you', 1378),\n",
              " ('he', 1084),\n",
              " ('is', 975),\n",
              " ('to', 920),\n",
              " ('a', 915),\n",
              " ('s', 651),\n",
              " ('not', 606),\n",
              " ('the', 548),\n",
              " ('we', 529),\n",
              " ('she', 521),\n",
              " ('am', 514),\n",
              " ('of', 411),\n",
              " ('are', 402),\n",
              " ('they', 380),\n",
              " ('very', 316),\n",
              " ('in', 314)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJMj5_jRcdte",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "cfecb6fa-1fed-4aaa-ea87-df577305ad0d"
      },
      "source": [
        "TRG.vocab.freqs.most_common(20)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 5970),\n",
              " ('estoy', 1281),\n",
              " ('el', 1083),\n",
              " ('de', 945),\n",
              " ('es', 902),\n",
              " ('no', 786),\n",
              " ('a', 680),\n",
              " ('soy', 553),\n",
              " ('un', 547),\n",
              " ('esta', 534),\n",
              " ('que', 443),\n",
              " ('ella', 420),\n",
              " ('en', 401),\n",
              " ('la', 378),\n",
              " ('eres', 357),\n",
              " ('me', 340),\n",
              " ('muy', 317),\n",
              " ('estamos', 265),\n",
              " ('una', 256),\n",
              " ('voy', 237)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}