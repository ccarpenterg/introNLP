{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04a_NLP_and_sequence-to-sequence_RNNs.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOiVY/y73C2FsnIP1pkcgiw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/introNLP/blob/master/04a_NLP_and_sequence_to_sequence_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12TvrvBulJba",
        "colab_type": "text"
      },
      "source": [
        "# NLP and Sequence-to-Sequence RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7C_h_GLDTbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.manythings.org/anki/spa-eng.zip\n",
        "!unzip spa-eng.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejo5g5kBECxP",
        "colab_type": "code",
        "outputId": "c4f7db8c-4ecb-46aa-897b-7b341e76998a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import TranslationDataset\n",
        "from torchtext import data\n",
        "\n",
        "import spacy\n",
        "\n",
        "from io import open\n",
        "\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import os\n",
        "\n",
        "print(\"Spacy version:\", spacy.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spacy version: 2.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8wUoQ65g2u6",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing the Natural Language Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAOScg5lgthG",
        "colab_type": "text"
      },
      "source": [
        "### Text Normalization functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64vE5FSE2tgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        char for char in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(char) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPudOEURc7Zl",
        "colab_type": "text"
      },
      "source": [
        "### Read Pairs function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_kg0w9K5XHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readPairs(pathToFile, slang, tlang):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    f = open(pathToFile, encoding='utf-8')\n",
        "    lines = f.read().strip().split('\\n')\n",
        "\n",
        "    pairs = [[normalizeString(s) for s in line.split('\\t')[:2]] for line in lines]\n",
        "\n",
        "    return pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-uO-hSZc2ao",
        "colab_type": "text"
      },
      "source": [
        "### Filter function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV0nAsYq8ClC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am\", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[0].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYAokqACdAxo",
        "colab_type": "text"
      },
      "source": [
        "### Prepare Data function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRDq95CW_ll8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepareData(pathToFile, slang, tlang):\n",
        "    pairs = readPairs(pathToFile, slang, tlang)\n",
        "    print(\"Read {} sentence pairs\".format(len(pairs)))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to {} sentence pairs\".format(len(pairs)))\n",
        "    return pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX7QHkDddJiq",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Indexes (Splits) function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFs44kLn_INN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def datasetIndexes(pairs, train=0.8, val=0.1):\n",
        "    num_examples = len(pairs)\n",
        "    indexes = list(range(num_examples))\n",
        "    last_train_idx = round(train*num_examples)\n",
        "    last_valid_idx = last_train_idx + round(val*num_examples)\n",
        "    random.shuffle(indexes)\n",
        "    train_idxs = indexes[:last_train_idx]\n",
        "    val_idxs = indexes[last_train_idx:last_valid_idx]\n",
        "    test_idxs = indexes[last_valid_idx:]\n",
        "    return train_idxs, val_idxs, test_idxs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTKk0Hc_dedI",
        "colab_type": "text"
      },
      "source": [
        "### Spanish-English Translation Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H19pHY6QPyF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SpanishEnglishDataset(TranslationDataset):\n",
        "    \"\"\"English to Spanish Dataset\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def splits(cls, exts, fields, root='.data/',\n",
        "               train='train', validation='val', test='test', **kwargs):\n",
        "        \n",
        "        if 'path' not in kwargs:\n",
        "            expected_folder = os.path.join(root, cls.name)\n",
        "            path = expected_folder if os.path.exists(expected_folder) else None\n",
        "        else:\n",
        "            path = kwargs['path']\n",
        "            del kwargs['path']\n",
        "        \n",
        "        return super(SpanishEnglishDataset, cls).splits(\n",
        "            exts, fields, path, root, train, validation, test, **kwargs\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QisIUx_5drmV",
        "colab_type": "text"
      },
      "source": [
        "## Spanish-English Dataset files (splits)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKp8BQP6DX6c",
        "colab_type": "code",
        "outputId": "f9d44e10-983c-4134-f39f-05d4c0984142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "pairs = prepareData('spa.txt', 'eng', 'spa')\n",
        "train_idxs, val_idxs, test_idxs = datasetIndexes(pairs)\n",
        "print(\"{} {} {}\".format(len(train_idxs), len(val_idxs), len(test_idxs) ))\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 123335 sentence pairs\n",
            "Trimmed to 7588 sentence pairs\n",
            "6070 759 759\n",
            "['he s your friend .', 'el es tu amigo .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf-RZx3YGSDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('train.en', 'w') as slang_file, open('train.es', 'w') as tlang_file:\n",
        "    for i in train_idxs:\n",
        "        slang_file.write(pairs[i][0] + '\\n')\n",
        "        tlang_file.write(pairs[i][1] + '\\n')\n",
        "\n",
        "with open('val.en', 'w') as slang_file, open('val.es', 'w') as tlang_file:\n",
        "    for i in val_idxs:\n",
        "        slang_file.write(pairs[i][0] + '\\n')\n",
        "        tlang_file.write(pairs[i][1] + '\\n')\n",
        "\n",
        "with open('test.en', 'w') as slang_file, open('test.es', 'w') as tlang_file:\n",
        "    for i in test_idxs:\n",
        "        slang_file.write(pairs[i][0] + '\\n')\n",
        "        tlang_file.write(pairs[i][1] + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SPfenbVeFlS",
        "colab_type": "text"
      },
      "source": [
        "## Loading the files (train, val, test) and Creating a SpanishDatatset instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jBTDFm1jgS8A",
        "colab": {}
      },
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download es"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y03SbEQ1X54e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spacy_es = spacy.load('es')\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "def tokenize_es(text):\n",
        "    \"\"\"\n",
        "    Tokenizes Spanish text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [token.text for token in spacy_es.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [token.text for token in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-37Cb1XYY-08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC = data.Field(tokenize=tokenize_en, init_token='<SOS>', eos_token='<EOS>', lower=True)\n",
        "TRG = data.Field(tokenize=tokenize_es, init_token='<SOS>', eos_token='<EOS>', lower=True)\n",
        "\n",
        "train_data, valid_data, test_data = SpanishEnglishDataset.splits(\n",
        "    path='',\n",
        "    exts=('.en', '.es'),\n",
        "    fields=(SRC, TRG)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYPDAg7YiSu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=5)\n",
        "TRG.build_vocab(train_data, min_freq=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVGpH1PiaLpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QIyVoSKcIfH",
        "colab_type": "code",
        "outputId": "a2851c07-0c7a-4413-a8a1-39863904ff59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(valid_data))\n",
        "print(len(test_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6070\n",
            "759\n",
            "759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRCx6WAEeg5P",
        "colab_type": "text"
      },
      "source": [
        "## Vocabulary and Training Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlMdtj01WXIU",
        "colab_type": "code",
        "outputId": "a572c9f5-fde2-4600-d391-aa3e6c75b615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "SRC.vocab.itos[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '<SOS>', '<EOS>', '.', 'i', 'm', 're', 'you', 'he']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7DsRjXshe0B",
        "colab_type": "code",
        "outputId": "45a42e96-2639-4864-f27f-505fc5406d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch = next(iter(train_iterator))\n",
        "\n",
        "src_example = batch.src[:, 0]\n",
        "src = ' '.join(map(lambda i: SRC.vocab.itos[i], src_example))\n",
        "trg_example = batch.trg[:, 0]\n",
        "trg = ' '.join(map(lambda i: TRG.vocab.itos[i], trg_example))\n",
        "\n",
        "print(\"English sentence:\", src)\n",
        "print(\"Spanish sentence:\", trg)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English sentence: <SOS> i m not good at lying . <EOS> <pad> <pad>\n",
            "Spanish sentence: <SOS> no soy bueno mintiendo . <EOS> <pad> <pad> <pad> <pad>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp2GwmBkcOsm",
        "colab_type": "code",
        "outputId": "5d6ccffe-a0d5-4d95-cdd2-473c2c8cafbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "SRC.vocab.freqs.most_common(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 5981),\n",
              " ('i', 2777),\n",
              " ('m', 2166),\n",
              " ('re', 1449),\n",
              " ('you', 1389),\n",
              " ('he', 1087),\n",
              " ('is', 975),\n",
              " ('to', 937),\n",
              " ('a', 910),\n",
              " ('s', 666)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJMj5_jRcdte",
        "colab_type": "code",
        "outputId": "10397f25-0bce-40c6-cd41-85c4b729524c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "TRG.vocab.freqs.most_common(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 5966),\n",
              " ('estoy', 1283),\n",
              " ('el', 1080),\n",
              " ('de', 961),\n",
              " ('es', 899),\n",
              " ('no', 793),\n",
              " ('a', 678),\n",
              " ('un', 560),\n",
              " ('esta', 547),\n",
              " ('soy', 525)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wz-vwqTiVZS",
        "colab_type": "text"
      },
      "source": [
        "## Sequence-to-Sequence (Seq2Seq) Model (without Attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIw5655Ln_pT",
        "colab_type": "text"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdvU822UiiY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim,\n",
        "                 hidden_dim, num_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim,\n",
        "                           num_layers, dropout=dropout)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src_sequences):\n",
        "\n",
        "        # src_sequences: (max sequences length, batch size)\n",
        "\n",
        "        seq_embeddings = self.dropout(self.embedding(src_sequences))\n",
        "\n",
        "        # src_seq_embeddings: (max sequences length, batch size, embedding dimension)\n",
        "\n",
        "        seq_hidden, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        # hidden = (num layers * num directions, batch size, hidden dim)\n",
        "        # cell = (num layers * num directions, batch size, hidden dim)\n",
        "\n",
        "        return hidden, cell"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xCwi9fDn6g2",
        "colab_type": "text"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mnj77LceFBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim,\n",
        "                 output_dim, num_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_di = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_num,\n",
        "                           num_layers, dropout=dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, seq_at_t, hidden, cell):\n",
        "\n",
        "        # seq_at_t: (batch size) -> vector of sequences at time t\n",
        "\n",
        "        seq_at_t = seq_at_t.unsqueeze(0)\n",
        "\n",
        "        # seq_at_t: (1, batch size)\n",
        "\n",
        "        seq_at_t_embedded = self.dropout(self.embedding(seq_at_t))\n",
        "\n",
        "        # seq_at_t_embedded: (1, batch size, embedding dim)\n",
        "        # hidden = (num layers * num directions, batch size, hidden dim)\n",
        "        # cell = (num layers * num directions, batch size, hidden dim)\n",
        "\n",
        "        output, (hidden, cell) = self.rnn(seq_at_t_embedded, (hidden, cell))\n",
        "\n",
        "        # num directions = 1\n",
        "        # output: (1, batch size, hidden dim)\n",
        "\n",
        "        pred_scores = self.fc(output.squeeze(0))\n",
        "\n",
        "        # pred_scores: (batch size, output dim)\n",
        "        # hidden = (num layers , batch size, hidden dim)\n",
        "        # cell = (num layers , batch size, hidden dim)\n",
        "\n",
        "        return pred_scores, hidden, cell"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUF3H8jGv-XF",
        "colab_type": "text"
      },
      "source": [
        "### Seq2Seq Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJDsq0ruwEtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "\n",
        "        # src: (max src length, batch size)\n",
        "        # trg: (max trg length, batch size)\n",
        "\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # outputs: tensor to store the decoder output\n",
        "        # outputs: (target max length, batch size, target vocab size)\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # we'll plug the last hidden states of the encoder in the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        # the first target sequence token: <sos>\n",
        "        seq_at_t = trg[0, :]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            pred_scores, hidden, cell = self.decoder(seq_at_t, hidden, cell)\n",
        "\n",
        "            outputs[t] = pred_scores\n",
        "\n",
        "            # teacher_force: Boolean\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            # argmax_token: Token\n",
        "            argmax_token = output.argmax(1)\n",
        "\n",
        "            # depending on teacher_forcing value, use the next token or argmax_token\n",
        "            seq_at_t = trg[t] if teacher_force else argmax_token\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}