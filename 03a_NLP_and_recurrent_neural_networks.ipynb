{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03a_NLP_and_recurrent_neural_networks.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOOt7iAoW9qCebiNrd2EmSN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/introNLP/blob/master/03a_NLP_and_recurrent_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAJlYbWTNvHd",
        "colab_type": "text"
      },
      "source": [
        "# NLP and Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sXrfA8cNfJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load Tensorflow 2\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAfH4Q25XWaj",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis of IMDB Movie Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfcdpXg0OYRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_validation_split = tfds.Split.TRAIN.subsplit([8, 2])\n",
        "\n",
        "(train_validation_data, test_data), info = tfds.load(\n",
        "    'imdb_reviews/subwords8k',\n",
        "    split = (train_validation_split, tfds.Split.TEST),\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "train_data, validation_data = train_validation_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjac4DW_PTZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = info.features['text'].encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUa7saWHX6E8",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing the Dataset with Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d8VVXDBnKa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 5000\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_batches = (\n",
        "    train_data\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_data))\n",
        ")\n",
        "\n",
        "validation_batches = (\n",
        "    validation_data\n",
        "    .padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(validation_data))\n",
        ")\n",
        "\n",
        "test_batches = (\n",
        "    test_data\n",
        "    .padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_data))\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaNuisK1sCcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for batch_example, labels in train_batches.take(2):\n",
        "    print(\"Batch shape:\", batch_example.shape)\n",
        "    print(\"Labels shape:\", labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe01nULVYB84",
        "colab_type": "text"
      },
      "source": [
        "## Sequence Processing with a Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDNauQFibOUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_v1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
        "    tf.keras.layers.LSTM(64, return_sequences=False),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_v1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF5tNlgJPZZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_v2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_v2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaSQeOaksLxU",
        "colab_type": "text"
      },
      "source": [
        "**Embeding layer**\n",
        "\n",
        "\n",
        "\n",
        "**LSTM layer**\n",
        "\n",
        "Cell: 64 x 64 + 64 x 64 (weights) + 64 (biases) = 8,256 parameters\n",
        "\n",
        "Update gate: 64 x 64 + 64 x 64 (weights) + 64 (biases) = 8,256 parameters\n",
        "\n",
        "Forget gate: 64 x 64 + 64 x 64 (weights) + 64 (biases) = 8,256 parameters\n",
        "\n",
        "Output gate: 64 x 64 + 64 x 64 (weights) + 64 (biases) = 8,256 parameters\n",
        "\n",
        "**Bidirectional**\n",
        "\n",
        "Forward LSTM: 33,024 parameters\n",
        "\n",
        "Backward LSTM: 33,024 parameters\n",
        "\n",
        "Total: 66,048 parameters\n",
        "\n",
        "**FC layer**\n",
        "\n",
        "The bidirectional layer outputs two activationn vectors, one for the forward LSTM and one for the backward LTSM, that gives us 128 activation units.\n",
        "\n",
        "64 * 128 weigths + 64 biases = 8,256 parameters\n",
        "\n",
        "**Dense classifier layer**\n",
        "\n",
        "1 * 64 weights + 1 bias = 64 parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATv2qeHDS2Jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_v3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_v3.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld5naDmHm04x",
        "colab_type": "text"
      },
      "source": [
        "## Training Our RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPhqww6RoTtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10\n",
        "VAL_STEPS = 30\n",
        "results = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iDK4BwcnAVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_v1.compile(loss='binary_crossentropy',\n",
        "                 optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "results['v1'] = model_v1.fit(train_batches, epochs=EPOCHS,\n",
        "                             validation_data=validation_batches,\n",
        "                             validation_steps=VAL_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dZEB3n3Ra4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_accuracy = model_v1.evaluate(test_batches, verbose=0)\n",
        "\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FroL56-EP8XD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_v2.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "results['v2'] = model_v2.fit(train_batches, epochs=EPOCHS,\n",
        "                             validation_data=validation_batches,\n",
        "                             validation_steps=VAL_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nN_JAIl1r1Yb",
        "colab": {}
      },
      "source": [
        "test_loss, test_accuracy = model_v2.evaluate(test_batches, verbose=0)\n",
        "\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndsdSbe5QyQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_v3.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "results['v3'] = model_v3.fit(train_batches, epochs=EPOCHS,\n",
        "                             validation_data=validation_batches,\n",
        "                             validation_steps=VAL_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HpyWDFJ3r4GX",
        "colab": {}
      },
      "source": [
        "test_loss, test_accuracy = model_v3.evaluate(test_batches, verbose=0)\n",
        "\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXxx3IUiZiGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_stats(training_results):\n",
        "\n",
        "    training_dict = training_results.history\n",
        "\n",
        "    acc = training_dict['accuracy']\n",
        "    val_acc = training_dict['val_accuracy']\n",
        "    loss = training_dict['loss']\n",
        "    val_loss = training_dict['val_loss']\n",
        "\n",
        "    epochs = range(1, EPOCHS + 1)\n",
        "\n",
        "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8dT3ACVsgq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_stats(results['v1'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkStNtdNskng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_stats(results['v2'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtc0Du05snU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_stats(results['v3'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}